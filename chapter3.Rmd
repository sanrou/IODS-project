---
title: "IODS course project"
author: "Santeri Rouhinen"
output:
  html_document:
    theme: cosmo
    toc: true
    toc_depth: 2
    fig_caption: true
    fig_width: 6
    fig_height: 4
    code_folding: show
---

# Chapter 3. Logistic regression

## Analysis part
1. Read data to local folder
2. Choose interesting variables
3. Explore the distributions of the selected variables
4. Use logistic regression to explore high alcohol use and the chosen variables
5. Explore the predictive power of the created model
6. Bonus 10-fold cross-validation

### 1.
```{r hideLibraryOutput, warning=FALSE, message=FALSE}
# Load required libraries
library(ggplot2)
library(dplyr)
library(boot)

# Load data from .csv
alc <- read.csv("data/student-alc.csv")

# Column names
colnames(alc)

```

Description of the data from the authors (truncated):
This data approach student achievement in secondary education of two Portuguese schools. The data attributes include student grades, demographic, social and school related features) and it was collected by using school reports and questionnaires. Two datasets are provided regarding the performance in two distinct subjects: Mathematics (mat) and Portuguese language (por). In [Cortez and Silva, 2008], the two datasets were modeled under binary/five-level classification and regression tasks. G3 is the final year grade (issued at the 3rd period), while G1 and G2 correspond to the 1st and 2nd period grades. 

[Link](https://archive.ics.uci.edu/ml/datasets/Student+Performance) to the data and a fuller description. 


### 2. 
Choose four interesting variables and present hypothesis about their relationship with alcohol consumption. I did not select DataCamp ones as the results are known already, except the final grade as that is an obvious one. 

19 activities - extra-curricular activities (binary: yes or no). I would imagine that activities predicts low alcohol use. Might not, as for example hockey youths in Finland consume a lot of alcohol. Interesting to see if there is any relation to high use. I would guess a marginally significant relation.

21 higher - wants to take higher education (binary: yes or no). Those with ambition should have less alcohol use if they are serious. Wanting to take higher education though is easy. Again, interesting to see any relation to high use. I would guess a low but still significant relation.

24 famrel - quality of family relationships (numeric: from 1 - very bad to 5 - excellent). Having poor family relationship I would imagine predicts high alcohol use. I would guess this to have the strongest relation to high alcohol use of my variable selections.

32 final grade (numeric: from 0 to 20, output target). Final grade should have some predictive value, but not very strong. At least as far as I can remember from the DataCamp exercise. This selection is a bit boring.


### 3.
```{r}

## Do some exploratory search with the chosen variables and alcohol use. 
# Draw a bar plot of high_use by activities. Gives graphs divided by activities.
g1 <- ggplot(alc, aes(x = high_use))
g1 + geom_bar() + facet_wrap("activities") + ggtitle("Students divided by extra activities (no/yes) to high users (F/T)") + xlab("High alcohol use (False/True)")
```

19 activities. Looks like there is a small effect of students having extra activities having less heavy alcohol users. The difference between active students and non-activity students is not large.

```{r}
# Draw a bar plot of high education aspirations and high alcohol use.
g2 <- ggplot(alc, aes(x = high_use))
g2 + geom_bar() + facet_wrap("higher") + ggtitle("Students divided by wanting to take higher education (no/yes) to high users (F/T)") + xlab("High alcohol use (False/True)")


# 21. Education. There are very few people not wanting to take higher education, so this variable should be very pointless in future analyses.

alc %>% group_by(higher, high_use) %>% summarise(count = n())
```

There are only 18 out of the 382 that are not interested in higher education. A bit surprising. High use was 1:1 in those not wanting to take higher education so at least my hypothesis holds, kind of. The n is so small one should not make statistical inferences. The ratio amongst those wanting to take higher education is about 1:3.5, much less than 1:1.

```{r}
# 24. Family relationship. 
# Do a histogram of relationship levels by high alcohol use.
g3 <- ggplot(alc, aes(x = high_use))
g3 + geom_bar() + facet_wrap("famrel") + ggtitle("Students divided by family relationships (1-5) to high users (F/T)") + xlab("High alcohol use (False/True)")
```

There seems to be more high alcohol users in those reporting poor family relationships. Fortunately those reporting very low relationships are a minority. Hypothesis stands strong.

```{r}
# 32. Final grade.
# Do boxplots of high and low alcohol users and their final grades (G3).
g4 <- ggplot(alc, aes(x = high_use, y = G3))
g4 + geom_boxplot() + ggtitle("Students' final grades grouped by alcohol use") + xlab("High alcohol use (False/True)") + ylab("Final grade")
```

There is a small difference between the high and low users. High users of alcohol have worse grades on average than low users. There is large overlap between the groups though.





### 4.

```{r}


## Doing the logistic regression model.
lrModel <- glm(high_use ~ activities + higher + famrel + G3, data = alc, family = "binomial")

summary(lrModel)

```

The model has only two variables that seem worthwhile: family relationships and the final grade. Activities and higher education aspirations have a low chance of being significant in predicting high alcohol use. Having good family relationship and good final grade predicts lower alcohol use in the model.

```{r}
# Compute odds ratios and confidence intervals from the model's coefficients
oddsR <- coef(lrModel) %>% exp
confI <- confint(lrModel) %>% exp

# Print odds ratios and confidence intervals. The confidence intervals of activities, higher education aspirations, and final grades span 1, meaning that there might be no predictive value with those variables. The family relations almost get to 1 also. 
cbind(oddsR, confI)



```
The hypotheses for family relationships and final gradesh still hold, but rather tenuously if one considers the confidence intervals. Final grades have odds ratio of 1:1.07 so while it might be marginally significant it is of little practical value. I'd say only the family relationships variable has any value.

### 5. 

Explore the predictive power of the model with the significant variables. I'm including only the family relationships as the final grades had only a marginally significant probability of having a significant parameter in  the model, and also spanning 1 in it's confidence interval.

```{r hideWarningChunck, warning=FALSE, message=FALSE}

# Refit the model with only family relationships
strippedModel <- glm(high_use ~ famrel, data = alc, family = "binomial")

# Predict the high use of alcohol using the stripped down model and the original (for interests sake).
predHighStripped <- predict(strippedModel, type = "response")
predHighAll <- predict(lrModel, type = "response")

# Add the probabilities to data structure alc
alc <- mutate(alc, probStripped = predHighStripped)
alc <- mutate(alc, probAll = predHighAll)

# Make predictions of high use
alc <- mutate(alc, predStripped = probStripped > 0.5)

```


```{r}
alc <- mutate(alc, predAll = probAll > 0.5)

# Check that code was fine. Look at the first twenty values
select(alc, famrel, high_use, probStripped, predStripped, probAll, predAll) %>% head(20)

table(high_use = alc$high_use, prediction = alc$predStripped)
# Hmm. There seems to be no high users predicted by the stripped down model. Count n of TRUE values in predStripped to make sure.
sum(alc$predStripped)

# No True values... Let's see then how the full model would fare.
table(high_use = alc$high_use, prediction = alc$predAll)

# Better, but not great. The sensitivity of the model with all variables is terrible (2/114), and the specificity is fine (258/268). 

# Lets compute the the total proportion of inaccurately classified individuals for hoots and giggles. Using the full model as the stripped version would be a bit boring to test.
nIndividuals <- nrow(alc)
nIncorrectPrediction <- sum(alc$high_use != alc$predAll)
nIncorrectPrediction/nIndividuals

# The proportion of inaccurate predictions were 32 % (122 out of 382). This gives an inflated view of how good the model is, as this mostly is due to the model having very few predictions for high usage.

# Let's compare the model to a simple strategy of if family relationship is 2 or less, then predict high alcohol use.
alc$simpleClassify <- alc$famrel <= 2
table(high_use = alc$high_use, prediction = alc$simpleClassify)

nIncorrectPrediction <- sum(alc$high_use != alc$simpleClassify)
nIncorrectPrediction/nIndividuals

```

The proportion of inaccurate predictions were 31 % (119 out of 382). The simple model was better than the full model, but not by much. The sensitivity increased to almost 50 % though which is much better than the full model. Less than 50 % chance is still not impressive though.




### 6.

Perform a 10-fold cross-validation of the full model. One needs to define a loss function for the cross-validation code (cv.glm).


```{r}

# Define loss function (average prediction error)
loss_func <- function(class, prob) {
  n_wrong <- abs(class - prob) > 0.5
  mean(n_wrong)
}

# compute the average number of wrong predictions in the (training) data
loss_func(class = alc$high_use, prob = alc$predAll)

# 10-fold cross-validation
library(boot)
cv <- cv.glm(data = alc, cost = loss_func, glmfit = lrModel, K = 10)

# average number of wrong predictions in the cross validation
cv$delta[1]

```

My full model has worse performance than the model in DataCamp, that is 0.32 vs 0.26, lower values being better. 